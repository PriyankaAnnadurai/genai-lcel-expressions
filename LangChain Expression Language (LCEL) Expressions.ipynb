{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
   "metadata": {
    "height": 62,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Load environment variables (OpenAI API Key)\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
   "metadata": {
    "height": 111
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "# Step 1: Vector Store Creation\n",
    "# Create a vector store from given texts\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "# Convert the vector store into a retriever\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2df87934-1697-405c-b460-5e9bfd16c792",
   "metadata": {
    "height": 134
   },
   "outputs": [],
   "source": [
    "# Step 2: Prompt Template\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "# Step 3: Model Definition\n",
    "# Define the OpenAI chat model\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "# Define an output parser to format the output\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
   "metadata": {
    "height": 116
   },
   "outputs": [],
   "source": [
    "# Step 4: LCEL Chain Definition\n",
    "# Define a RunnableMap that processes input to extract context, format the prompt, and generate an answer\n",
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
   "metadata": {
    "height": 80
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Harrison worked at Kensho.\n",
      "Response 2: Bears like to eat honey.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Testing the Chain\n",
    "# Example questions for testing\n",
    "question_1 = {\"question\": \"where did harrison work?\"}\n",
    "question_2 = {\"question\": \"what do bears like to eat?\"}\n",
    "\n",
    "# Invoke the chain for each question\n",
    "response_1 = chain.invoke(question_1)\n",
    "response_2 = chain.invoke(question_2)\n",
    "\n",
    "# Print the outputs\n",
    "print(f\"Response 1: {response_1}\")\n",
    "print(f\"Response 2: {response_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
   "metadata": {
    "height": 73
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from inputs.invoke: {'context': [Document(page_content='harrison worked at kensho'), Document(page_content='bears like to eat honey')], 'question': 'where did harrison work?'}\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Inputs Handling (Optional, Additional Example)\n",
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})\n",
    "\n",
    "# Test with inputs.invoke\n",
    "response_from_inputs = inputs.invoke({\"question\": \"where did harrison work?\"})\n",
    "print(f\"Response from inputs.invoke: {response_from_inputs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
